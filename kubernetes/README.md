## Ilyas Latypov, MADE 2022, MLOps
### HW4 Kubernetes


### Особенности решения
Для установки Kubernetes воспользовался встроенным функционалом Docker Desktop (Win10 WSL2). Скрины приложены
Домашнее задание 2 по online inference я не выполнял
Поэтому для выполнения домашнего задания 4 за место online-inference использовал  "заглушку"  docker-tutorial,
который поставляется вместе с Docker Desktop (скрин приложен) и доступен через http://localhost:80


### Ответы на вопросы домашнего задания
3. Пропишите Requests / Limits и напишите, зачем это нужно:
Это нужно для управления ресурсами, что бы ресурсов хватало и не тратились лишнее.
Requests - это минимальные требования к ресурсам необходимых контейнеру, а Limits  - это максимальные требования. 

4. Добавьте Liveness и Readiness пробы и посмотрите, что будет происходить. Напишите в описании -- чего вы этим добились.
Состояние READY появляется только после задержки, а еще череp минуту приложение перезапуститься (закрытие+запуск). Потом все повторяется заного и т.д.

5. Ответьте на вопрос, что будет, если сменить docker образ в манифесте и одновременно с этим:
    уменьшить/увеличить число реплик.  Поды с какими версиями образа будут внутри кластера?
Если уменьшить число реплик, то просто удаляется часть реплик, версия реплик не изменится.
Если увеличить число реплик, то добавятся новые реплики с другой версией образа, версии старых реплик не изменятся.

6. Опишите [Deployment] для вашего приложения:
a) Есть момент времени, когда на кластере существуют как все старые поды, так и все новые. 
Это достигается следующими настройками (maxSurge: 3, maxUnavailable: 0). 
В этом случае сначала запускаются новые Pod, а только потом закрываются старые. Получается, что есть промежуток времени когда запущены и старые и новые Pod
б) Одновременно с поднятием новых версий, гасятся старые.
Это достигается следующими настройками (maxSurge: 1, maxUnavailable: 0).
В этом случае одновремено запускаются новые Pod и закрываются старые


### Описание команд
  - "kubectl apply -f online-inference-pod.yaml"                  - Запуск 
  -  "kubectl get pods"          			                            - Проверка статуса pod
  - "kubectl port-forward pods/online-inference 8000:8000"        - Настройка портов


### Project
    ├── hello-world-docker                                        - Docker файлы для "заглушки" online-inference
    │   ├── Dockerfile
    │   └── hello.sh
    ├── Kubernetes_for_WSL2_WIN10.png                    	      - Скриншот установки
    ├── Running Kubernetes.png                                    - Скриншот запуска
    ├── online-inference-pod.yaml                           	  - простой манифест
    ├── online-inference-pod-resources.yaml                 	  - манифест с Requests / Limits
    ├── online-inference-pod-probes.yaml                  	    - манифест запуска с задержкой
    ├── online-inference-replicaset.yaml                         	- манифест с репликами
    ├── online-inference-deployment-blue-green.yaml               - манифест (старые и новые поды есть одновременно)
    ├── online-inference-deployment-rolling-update.yaml           - манифест (с поднятием новых версий, закрываются старые)
    └── README.md                                                 - Description


### Самооценка
+   1. Разверните Kubernetes (5 баллов) - сделано
+   2. Напишите простой Pod manifest для вашего приложения, назовите его online-inference-pod.yaml. Приложите скриншот, где видно, что все поднялось (4 балла) - сделано
+   3. Пропишите Requests / Limits и напишите, зачем это нужно в описании PR. Закоммитьте файл online-inference-pod-resources.yaml (2 балла) - сделано
+   4. Модифицируйте свое приложение так, чтобы оно стартовало не сразу (с задержкой 20-30 секунд) и падало спустя минуты работы (3 балла) - сделано
+   5. Сделайте 3 реплики вашего приложения (3 балла) - сделано
+   6. Опишите [Deployment] для вашего приложения (3 балла) - сделано


+ Итого: 20 баллов
